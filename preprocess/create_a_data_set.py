import sys
sys.path.append('/home/liyang/github repos/CS598_PROJECT-20240428/CS598_PROJECT')

# -*- coding: utf-8 -*-
"""create_data_set.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sh7VQCwkKTK197OEBtSH9gUPvy7ZPdLe
"""

import pandas as pd
from pyhealth.medcode import CrossMap, InnerMap
import pandas as pd

# Function to read the patient CSV file
def read_patient():
    return pd.read_csv("./CS598_PROJECT/data/PATIENTS.csv")

# Function to read the visit CSV file
def read_visit():
    return pd.read_csv('./CS598_PROJECT/data/ADMISSIONS.csv')

# Function to read the ICD_DIAGNOSES dictionary CSV file
def read_icd9_code():
    return pd.read_csv('./CS598_PROJECT/data/D_ICD_DIAGNOSES.csv')

# Function to read the diagnosis CSV file
def read_diagnosis():
    return pd.read_csv("./CS598_PROJECT/data/DIAGNOSES_ICD.csv")

# Function to read the medication CSV file
def read_medication():
    return pd.read_csv("./CS598_PROJECT/data/PRESCRIPTIONS.csv", low_memory=False)

# Function to preprocess the patient dataframe
def preprocess_patient(df):
    selected_columns = ['SUBJECT_ID','DOB','DOD']
    return df[selected_columns].copy()

# Function to preprocess the visit dataframe
def preprocess_visit(df):
    selected_columns = ['SUBJECT_ID','HADM_ID','ADMITTIME','DISCHTIME','DEATHTIME']
    return df[selected_columns].copy()

# Function to preprocess the diagnosis dataframe
def preprocess_diagnosis(df):
    selected_columns = ['SUBJECT_ID','HADM_ID','ICD9_CODE']
    return df[selected_columns].copy()

# Function to preprocess the medication dataframe
def preprocess_medication(df):
    selected_columns = ['SUBJECT_ID','HADM_ID','STARTDATE','ENDDATE','DRUG_TYPE','DRUG']
    return df[selected_columns].copy()


## read data set

patient_raw = read_patient()
patient_df = preprocess_patient(patient_raw)

visit_raw = read_visit()
visit_df = preprocess_visit(visit_raw)

diagnosis_raw = read_diagnosis()
diagnosis_df = preprocess_diagnosis(diagnosis_raw)

medication_raw = read_medication()
medication_df = preprocess_medication(medication_raw)

## create ICD9 token2index

icd9cm = InnerMap.load("ICD9CM")

icd9_code_dictionary = read_icd9_code()

ancestors = list(set([j for i in icd9_code_dictionary['ICD9_CODE'] for j in icd9cm.get_ancestors(i) if '.' not in j]))
icd9_token2idx = {ancestors[i] : i for i in range(len(ancestors))}
icd9_idx2token = {i : ancestors[i] for i in range(len(ancestors))}
icd9_token2idx['UNK'] = len(ancestors)
icd9_token2idx['MASK'] = len(ancestors)+1
icd9_token2idx['PAD'] = len(ancestors)+2
icd9_token2idx['SEP'] = len(ancestors)+3
icd9_token2idx['CLS'] = len(ancestors)+4

icd9_idx2token[len(ancestors)] = 'UNK'
icd9_idx2token[len(ancestors)+1] = 'MASK'
icd9_idx2token[len(ancestors)+2] = 'PAD'
icd9_idx2token[len(ancestors)+3] = 'SEP'
icd9_idx2token[len(ancestors)+4] = 'CLS'

def icd9_ancestor(row):
  row = str(row)
  if len(row) == 0 or row not in icd9cm:
    return row
  df_ancestors = [i for i in icd9cm.get_ancestors(row) if '.' not in i]
  return df_ancestors[0] if len(df_ancestors) > 0 else df_ancestors

def icd9_mapping(row):
  if len(row) == 0 or row not in ancestors:
    return row
  return icd9_token2idx[str(row)]

# Add Age
patient_df['DOB'] = pd.to_datetime(patient_df['DOB']).dt.date
visit_df['ADMITTIME'] = pd.to_datetime(visit_df['ADMITTIME']).dt.date
df = visit_df.merge(patient_df, on='SUBJECT_ID')
df = df.merge(diagnosis_df, on=['SUBJECT_ID', 'HADM_ID'])
df['AGE'] = (df['ADMITTIME'] - df['DOB']).apply(lambda x: int(x.days/365))
subject_id_counts = df.groupby('SUBJECT_ID')['ADMITTIME'].nunique()
# filter out the patient with less than 2 visits
valid_subject_ids = subject_id_counts[subject_id_counts > 1].index
df = df[df['SUBJECT_ID'].isin(valid_subject_ids)].copy()

# Add ICD9_CODE
df['ICD9_CODE_ANCESTOR'] = df['ICD9_CODE'].apply(icd9_ancestor)
df['ICD9_CODE_ANCESTOR_INDEX'] = df['ICD9_CODE_ANCESTOR'].apply(icd9_mapping)

index = [False if isinstance(i, list) else True for i in df['ICD9_CODE_ANCESTOR_INDEX']]
df = df.iloc[index]
df = df.reset_index(drop = True)

# group by date
diagnoses = df.sort_values(by=['SUBJECT_ID', 'ADMITTIME'])
diagnoses_grouped = diagnoses.groupby(['SUBJECT_ID', 'ADMITTIME']).agg({'ICD9_CODE_ANCESTOR_INDEX': list, 'AGE': list, 'DOB': 'first'}).reset_index()
diagnoses_grouped.columns = ['SUBJECT_ID', 'ADMITTIME', 'ICD9_CODE', 'AGE', 'DOB']

# diagnoses_grouped.head(20)
token2idx = {'token2idx' :icd9_token2idx, 'idx2token' : icd9_idx2token}

import pickle
with open('./CS598_PROJECT/output/token2idx.pkl', 'wb') as pickle_file:
    pickle.dump(token2idx , pickle_file)

diagnoses_final = diagnoses_grouped[["SUBJECT_ID", "ADMITTIME", "DOB", "ICD9_CODE", "AGE"]]

diagnoses_final["NEW_AGE"] = diagnoses_final['AGE'].apply(lambda x: x + [x[0]])
diagnoses_final["NEW_ICD9_CODE"] = diagnoses_final["ICD9_CODE"].apply(lambda x: x + ["SEP"])
# diagnoses_final.head(20)

diagnoses_grouped_final = diagnoses_final.sort_values(by=['ADMITTIME'], ascending=True).groupby(['SUBJECT_ID']).agg({'NEW_ICD9_CODE': list, 'NEW_AGE': list}).reset_index()
diagnoses_grouped_final["ICD9_CODE"] = diagnoses_grouped_final["NEW_ICD9_CODE"].apply(lambda nested_list: [item for sublist in nested_list for item in sublist])
diagnoses_grouped_final["AGE"] = diagnoses_grouped_final["NEW_AGE"].apply(lambda nested_list: [item for sublist in nested_list for item in sublist])
diagnoses_grouped_final.drop(["NEW_ICD9_CODE", "NEW_AGE"], axis = 1, inplace=True)
diagnoses_grouped_final.columns = ['SUBJECT_ID', 'ICD9_CODE', 'AGE']
#diagnoses_grouped_final.head(50)

# diagnoses_grouped_final.to_csv('/content/drive/MyDrive/CS598_PROJECT/output/diagnoses.csv', index=False)
# File path to save the pickle file
file_path = './CS598_PROJECT/output/dataset.pkl'

# Save the DataFrame to a pickle file using pandas
diagnoses_grouped_final.to_pickle(file_path)


# NextXVisit: train test split
# Remove the last observation for each subject
dataset_NextXVisit_grouped = diagnoses.groupby(['SUBJECT_ID', 'ADMITTIME']).agg({'ICD9_CODE_ANCESTOR_INDEX': list, 'AGE': list, 'DOB': 'first'}).reset_index()

dataset_NextXVisit_label = dataset_NextXVisit_grouped.groupby(['SUBJECT_ID']).tail(1).reset_index(drop = True)
dataset_NextXVisit_value = dataset_NextXVisit_grouped.groupby(['SUBJECT_ID']).apply(lambda group: group.iloc[:-1]).reset_index(drop = True)
dataset_NextXVisit_label.columns = ['SUBJECT_ID', 'ADMITTIME', 'ICD9_CODE_LABEL', 'AGE', 'DOB']
dataset_NextXVisit_value.columns = ['SUBJECT_ID', 'ADMITTIME', 'ICD9_CODE', 'AGE', 'DOB']

# dataset_NextXVisit_grouped.head(5)

dataset_NextXVisit_value_final = dataset_NextXVisit_value[["SUBJECT_ID", "ADMITTIME", "DOB", "ICD9_CODE", "AGE"]]

dataset_NextXVisit_value_final["NEW_AGE"] = dataset_NextXVisit_value_final['AGE'].apply(lambda x: x + [x[0]])
dataset_NextXVisit_value_final["NEW_ICD9_CODE"] = dataset_NextXVisit_value_final["ICD9_CODE"].apply(lambda x: x + ["SEP"])

dataset_NextXVisit_value_final = dataset_NextXVisit_value_final.sort_values(by=['ADMITTIME'], ascending=True).groupby(['SUBJECT_ID']).agg({'NEW_ICD9_CODE': list, 'NEW_AGE': list}).reset_index()
dataset_NextXVisit_value_final["ICD9_CODE"] = dataset_NextXVisit_value_final["NEW_ICD9_CODE"].apply(lambda nested_list: [item for sublist in nested_list for item in sublist])
dataset_NextXVisit_value_final["AGE"] = dataset_NextXVisit_value_final["NEW_AGE"].apply(lambda nested_list: [item for sublist in nested_list for item in sublist])
dataset_NextXVisit_value_final.drop(["NEW_ICD9_CODE", "NEW_AGE"], axis = 1, inplace=True)
dataset_NextXVisit_value_final.columns = ['SUBJECT_ID', 'ICD9_CODE', 'AGE']

dataset_NextXVisit = pd.merge(dataset_NextXVisit_value_final, dataset_NextXVisit_label.loc[:,["SUBJECT_ID", "ICD9_CODE_LABEL"]], on='SUBJECT_ID', how='left')


train_index = dataset_NextXVisit.loc[:, "SUBJECT_ID"].sample(200, random_state=59)
NextXVisit_train = dataset_NextXVisit.iloc[train_index.index, :]
NextXVisit_test = dataset_NextXVisit.iloc[~dataset_NextXVisit.index.isin(train_index.index), :]

NextXVisit_file_path = './CS598_PROJECT/output/NextXVisitdataset.pkl'
NextXVisit_test_file_path = './CS598_PROJECT/output/NextXVisit_train.pkl'
NextXVisit_train_file_path = './CS598_PROJECT/output/NextXVisit_test.pkl'


# Save the DataFrame to a pickle file using pandas
dataset_NextXVisit.to_pickle(NextXVisit_file_path)
NextXVisit_train.to_pickle(NextXVisit_train_file_path)
NextXVisit_test.to_pickle(NextXVisit_test_file_path)

